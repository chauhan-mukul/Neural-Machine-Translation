{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b34b6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from string import digits\n",
    "from keras.models import Model\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d760cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=pd.read_csv(r\"E:\\Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4864d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  politicians do not have permission to do what ...   \n",
       "1        ted         I'd like to tell you about one such child,   \n",
       "2  indic2012  This percentage is even greater than the perce...   \n",
       "3        ted  what we really mean is that they're bad at not...   \n",
       "4  indic2012  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0d404992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127607, 3)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b9122b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37554</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>सन् 330 ईसापूर्व में मकदूनिया (यूनान) के विजेत...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59804</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>लेकिन उस समय इस्लाम का उदय नहीं हुआ था; ईरान क...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source english_sentence  \\\n",
       "37554  indic2012              NaN   \n",
       "59804  indic2012              NaN   \n",
       "\n",
       "                                          hindi_sentence  \n",
       "37554  सन् 330 ईसापूर्व में मकदूनिया (यूनान) के विजेत...  \n",
       "59804  लेकिन उस समय इस्लाम का उदय नहीं हुआ था; ईरान क...  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['english_sentence'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a6d35c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['hindi_sentence'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7b8e66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8f3e8df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127605, 3)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "85bb05ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37724\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "10ff1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7b48dc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124827, 3)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape #after dropping duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d8f6049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines.sample(n=25000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1b3353d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0f9931bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cbd775e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "298612c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude.add('“')\n",
    "exclude.add('”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1bc3527d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '“',\n",
       " '”'}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cc2d07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to remove all of the special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9bf38429",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b23a4c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25520</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>islam is word from arabic and it full word is ...</td>\n",
       "      <td>इस्लाम शब्द अरबी भाषा का शब्द है जिसका मूल शब्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118633</th>\n",
       "      <td>ted</td>\n",
       "      <td>everything is reliant on these computers working</td>\n",
       "      <td>इन कंप्यूटरों पर सब कुछ निर्भर है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113495</th>\n",
       "      <td>tides</td>\n",
       "      <td>parliament does not control the government</td>\n",
       "      <td>संसद का सरकार पपर नियंत्रण नपहीं रहता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>tides</td>\n",
       "      <td>race equality new laws</td>\n",
       "      <td>नये कानून नस्ली समानता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111804</th>\n",
       "      <td>tides</td>\n",
       "      <td>the provision would not affect the power of pa...</td>\n",
       "      <td>व्यवसायों आदि से होने वाली आय के बारे में विधि...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "25520   indic2012  islam is word from arabic and it full word is ...   \n",
       "118633        ted   everything is reliant on these computers working   \n",
       "113495      tides        parliament does not control the government    \n",
       "29783       tides                             race equality new laws   \n",
       "111804      tides  the provision would not affect the power of pa...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "25520   इस्लाम शब्द अरबी भाषा का शब्द है जिसका मूल शब्...  \n",
       "118633                 इन कंप्यूटरों पर सब कुछ निर्भर है   \n",
       "113495             संसद का सरकार पपर नियंत्रण नपहीं रहता   \n",
       "29783                              नये कानून नस्ली समानता  \n",
       "111804  व्यवसायों आदि से होने वाली आय के बारे में विधि...  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "084692e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing extra space\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d40e40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "aea31536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25520</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>islam is word from arabic and it full word is ...</td>\n",
       "      <td>START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118633</th>\n",
       "      <td>ted</td>\n",
       "      <td>everything is reliant on these computers working</td>\n",
       "      <td>START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113495</th>\n",
       "      <td>tides</td>\n",
       "      <td>parliament does not control the government</td>\n",
       "      <td>START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>tides</td>\n",
       "      <td>race equality new laws</td>\n",
       "      <td>START_ नये कानून नस्ली समानता _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111804</th>\n",
       "      <td>tides</td>\n",
       "      <td>the provision would not affect the power of pa...</td>\n",
       "      <td>START_ व्यवसायों आदि से होने वाली आय के बारे म...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "25520   indic2012  islam is word from arabic and it full word is ...   \n",
       "118633        ted   everything is reliant on these computers working   \n",
       "113495      tides         parliament does not control the government   \n",
       "29783       tides                             race equality new laws   \n",
       "111804      tides  the provision would not affect the power of pa...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "25520   START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...  \n",
       "118633      START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END  \n",
       "113495  START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END  \n",
       "29783                  START_ नये कानून नस्ली समानता _END  \n",
       "111804  START_ व्यवसायों आदि से होने वाली आय के बारे म...  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b82bfb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2c8075fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25520</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>islam is word from arabic and it full word is ...</td>\n",
       "      <td>START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118633</th>\n",
       "      <td>ted</td>\n",
       "      <td>everything is reliant on these computers working</td>\n",
       "      <td>START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113495</th>\n",
       "      <td>tides</td>\n",
       "      <td>parliament does not control the government</td>\n",
       "      <td>START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>tides</td>\n",
       "      <td>race equality new laws</td>\n",
       "      <td>START_ नये कानून नस्ली समानता _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111804</th>\n",
       "      <td>tides</td>\n",
       "      <td>the provision would not affect the power of pa...</td>\n",
       "      <td>START_ व्यवसायों आदि से होने वाली आय के बारे म...</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "25520   indic2012  islam is word from arabic and it full word is ...   \n",
       "118633        ted   everything is reliant on these computers working   \n",
       "113495      tides         parliament does not control the government   \n",
       "29783       tides                             race equality new laws   \n",
       "111804      tides  the provision would not affect the power of pa...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "25520   START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका ...   \n",
       "118633      START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END   \n",
       "113495  START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END   \n",
       "29783                  START_ नये कानून नस्ली समानता _END   \n",
       "111804  START_ व्यवसायों आदि से होने वाली आय के बारे म...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "25520                    14                   21  \n",
       "118633                    7                    9  \n",
       "113495                    6                    9  \n",
       "29783                     4                    6  \n",
       "111804                   22                   24  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7ec8bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2435, 5)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e7c039ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence: 314\n",
      "maximum length of English Sentence  348\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence:\",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "fe2ec71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as with terrorism the concept of state terrorism is controversial the chairman of the united nations counterterrorism committee has stated that the committee was conscious of international conventions on the subject and none of them referred to state terrorism which was not an international legal concept if states abused their power they should be judged against international conventions dealing with war crimes international human rights and international humanitarian law former united nations secretarygeneral kofi annan has said that it is time to set aside debates on socalled state terrorism the use of force by states is already thoroughly regulated under international law however he also made clear that regardless of the differences between governments on the question of definition of terrorism what is clear and what we can all agree on is any deliberate attack on innocent civilians regardless of ones cause is unacceptable and fits into the definition of terrorismstate terrorism has been used to refer to terrorist acts by governmental agents or forces this involves the use of state resources employed by a states foreign policies such as using its military to directly perform acts of terrorism professor of political science michael stohl cites the examples that include germanys bombing of london and the us atomic destruction of hiroshima during world war ii he argues that the use of terror tactics is common in international relations and the state has been and remains a more likely employer of terrorism within the international system than insurgents they also cite the first strike option as an example of the terror of coercive diplomacy as a form of this which holds the world hostage with the implied threat of using nuclear weapons in crisis management they argue that the institutionalized form of terrorism has occurred as a result of changes that took place following world war ii in this analysis state terrorism exhibited as a form of foreign policy was shaped by the presence and use of weapons of mass destruction and that the legitimizing of such violent behavior led to an increasingly accepted form of this state behavior']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lines[lines['length_eng_sentence']==348]['english_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6a361bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START_ राज्य आतंकवाद की अवधारणा विवादास्पद है राज्यों द्वारा सैन्य कार्रवाई के दौरान युद्ध आम तौर पर आतंकवाद तब भी जब वे महत्वपूर्ण नागरिक हताहत शामिल विचार नहीं कर रहे हैंअध्यक्ष ने संयुक्त राष्ट्र काउंटर के आतंकवाद समिति का मानना है कि इस समिति इस विषय पर अंतरराष्ट्रीय समझौतों के प्रति जागरूक किया गया हैं और उनमें से कोई भी नहीं है जो एक अंतरराष्ट्रीय कानूनी अवधारणा नहीं थी राज्य आतंकवाद को भेजायदि राज्यों को उनकी सत्ता का दुरुपयोग वे अंतरराष्ट्रीय सम्मेलनों से निपटने के खिलाफ न्याय किया जाना चाहिए युद्ध अपराधों war crimes अंतरराष्ट्रीय मानव अधिकार और अंतर्राष्ट्रीय मानवीय कानून international humanitarian lawपूर्व संयुक्त राष्ट्रमहासचिव secretarygeneralकोफी अन्नान कि यह कथित पर बहस अलग सेट करने के लिए समय है ने कहा है कि राज्य के आतंकवाद इस राज्यों द्वारा बल का प्रयोग use of force by states पहले से ही पूरी तरह अंतरराष्ट्रीय कानून के तहत विनियमित है हालांकि उन्होंने यह भी कहा कि चाहे आतंकवाद की परिभाषा के प्रश्न पर सरकारों के बीच के अंतर के क्या है और स्पष्ट है हम सब पर क्या सहमत कर सकते हैं स्पष्ट कर दिया निर्दोष नागरिकों पर किसी भी विचार पर हमला चाहे एक के कारण की है है अस्वीकार्य है और आतंकवाद की परिभाषा में हो गया _END']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lines[lines['length_eng_sentence']==348]['hindi_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5f9357e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "46041adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16520, 5)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "47ea0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "54fdb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating hindi and english vocabulary\n",
    "all_eng_words=set()\n",
    "for english in lines['english_sentence']:\n",
    "    for word in english.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a96148e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17047"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8ebed6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19333"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7ec76c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "99cde183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17047, 19333)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "75997d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens+=1 #for zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "30fd104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "44e03759",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "1928a289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118633</th>\n",
       "      <td>ted</td>\n",
       "      <td>everything is reliant on these computers working</td>\n",
       "      <td>START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113495</th>\n",
       "      <td>tides</td>\n",
       "      <td>parliament does not control the government</td>\n",
       "      <td>START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>tides</td>\n",
       "      <td>race equality new laws</td>\n",
       "      <td>START_ नये कानून नस्ली समानता _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57202</th>\n",
       "      <td>ted</td>\n",
       "      <td>there was lasagna there was casseroles</td>\n",
       "      <td>START_ वहां लाजान्या था कैसेरोल थे _END</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107821</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>super power india source google writer vedprat...</td>\n",
       "      <td>START_ महाशक्ति भारत गूगल पुस्तक लेखक वेदप्रता...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85746</th>\n",
       "      <td>tides</td>\n",
       "      <td>each was a blow to conservatism</td>\n",
       "      <td>START_ इनमें से प्रत्येक यथास्थितिवादियों पर च...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55848</th>\n",
       "      <td>tides</td>\n",
       "      <td>the colour of the drake is black at the neck a...</td>\n",
       "      <td>START_ नर बतख का रंग गर्दन और पीठ पर काला होता...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103460</th>\n",
       "      <td>ted</td>\n",
       "      <td>in the mathare valley slums</td>\n",
       "      <td>START_ माथेरा घाटी की झुग्गियों में। _END</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91981</th>\n",
       "      <td>ted</td>\n",
       "      <td>the second time was a procedure that involved ...</td>\n",
       "      <td>START_ दूसरी बार के उपचार में बेहोश करने की आव...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101360</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>uttarpradesh a mirrorlive hindustan</td>\n",
       "      <td>START_ उत्तर प्रदेश एक आईना लाइव हिन्दुस्तान _END</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "118633        ted   everything is reliant on these computers working   \n",
       "113495      tides         parliament does not control the government   \n",
       "29783       tides                             race equality new laws   \n",
       "57202         ted             there was lasagna there was casseroles   \n",
       "107821  indic2012  super power india source google writer vedprat...   \n",
       "85746       tides                    each was a blow to conservatism   \n",
       "55848       tides  the colour of the drake is black at the neck a...   \n",
       "103460        ted                        in the mathare valley slums   \n",
       "91981         ted  the second time was a procedure that involved ...   \n",
       "101360  indic2012                uttarpradesh a mirrorlive hindustan   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "118633      START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END   \n",
       "113495  START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END   \n",
       "29783                  START_ नये कानून नस्ली समानता _END   \n",
       "57202             START_ वहां लाजान्या था कैसेरोल थे _END   \n",
       "107821  START_ महाशक्ति भारत गूगल पुस्तक लेखक वेदप्रता...   \n",
       "85746   START_ इनमें से प्रत्येक यथास्थितिवादियों पर च...   \n",
       "55848   START_ नर बतख का रंग गर्दन और पीठ पर काला होता...   \n",
       "103460          START_ माथेरा घाटी की झुग्गियों में। _END   \n",
       "91981   START_ दूसरी बार के उपचार में बेहोश करने की आव...   \n",
       "101360  START_ उत्तर प्रदेश एक आईना लाइव हिन्दुस्तान _END   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "118633                    7                    9  \n",
       "113495                    6                    9  \n",
       "29783                     4                    6  \n",
       "57202                     6                    7  \n",
       "107821                    8                    9  \n",
       "85746                     6                   10  \n",
       "55848                    12                   13  \n",
       "103460                    5                    7  \n",
       "91981                    10                   12  \n",
       "101360                    4                    8  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lines = shuffle(lines)\n",
    "lines.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "7f9861a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding_data=list(lines['english_sentence'])\n",
    "# decoding_data=list(lines['hindi_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d88b529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "cd78e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len=20\n",
    "# trunc_dim='post'\n",
    "# oov_token=\"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "0ccbd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_eng=Tokenizer(num_words=num_encoder_tokens+1)\n",
    "# tokenizer_eng.fit_on_texts(encoding_data)\n",
    "# word_index_eng=tokenizer_eng.word_index\n",
    "# input_token=tokenizer_eng.texts_to_sequences(encoding_data)\n",
    "# padded_input_token=pad_sequences(sequences=input_token,maxlen=max_len,padding=trunc_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "4d8b2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_input_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "d5b613df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (word_index_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "689b5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_hindi=Tokenizer(num_words=num_decoder_tokens+1)\n",
    "# tokenizer_hindi.fit_on_texts(decoding_data)\n",
    "# word_index_hindi=tokenizer_hindi.word_index\n",
    "# target_token=tokenizer_hindi.texts_to_sequences(decoding_data)\n",
    "# padded_output_token=pad_sequences(sequences=target_token,maxlen=max_len,padding=trunc_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "73f0ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_output_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "cb7bb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(word_index_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "bb5d2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word_hindi[19333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f39a8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word_hindi=tokenizer_hindi.index_word\n",
    "# index_to_word_eng=tokenizer_eng.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "b5843a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13216,), (3304,))"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y =lines['english_sentence'],lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "89ca3c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39389          and im earning more than the footballers wow\n",
       "124244    yamuna joins ganga at allahabad from the left ...\n",
       "114346                          i have spent my entire life\n",
       "88938     to some extent farooq is nervous about the ong...\n",
       "2249      he had all the weaknesses of a normal human be...\n",
       "                                ...                        \n",
       "19102      okay so lets have a look at a little bit of data\n",
       "51342     it has also been recommended as a core element...\n",
       "20089                darwin also has a lot of other talents\n",
       "40877                                the human being played\n",
       "44343                             i want to understand them\n",
       "Name: english_sentence, Length: 13216, dtype: object"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "dd746ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def genrate_batch(X=X_train,y=y_train,batch_size=128):\n",
    "#     while True:\n",
    "#         for j in range(0, len(X), batch_size):\n",
    "#             input_batch=[]\n",
    "#             output_batch=[]\n",
    "#             decoder_target_data = np.zeros((batch_size, 20, num_decoder_tokens+1),dtype='float32')\n",
    "#             for i, (input_text, output_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "#                 output_t=output_text.copy()\n",
    "#                 for t,token in enumerate(output_text):\n",
    "#                     if token==0.0:\n",
    "#                         output_t[t-1]=0.0\n",
    "#                     if t>0:\n",
    "#                         decoder_target_data[i,t-1,token]=1\n",
    "#                 input_batch.append(list(input_text))\n",
    "#                 output_batch.append(list(output_t))\n",
    "#             yield ([np.asarray(input_batch),np.asarray(output_batch)],decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "2802552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "018b3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "06bcb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "90f1d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "28b7eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs=Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "8e84a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "#\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "70073033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "72c69cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, None, 300)    5114100     ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, None, 300)    5800200     ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  [(None, 300),        721200      ['embedding_8[0][0]']            \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)                  [(None, None, 300),  721200      ['embedding_9[0][0]',            \n",
      "                                 (None, 300),                     'lstm_8[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_8[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, None, 19334)  5819534     ['lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,176,234\n",
      "Trainable params: 18,176,234\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "3fb4ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "# len(X_train)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "9c154c9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_35132\\2108290721.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 21s 208ms/step - loss: 3.4177 - val_loss: 3.5137\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 19s 182ms/step - loss: 3.2433 - val_loss: 3.4145\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 19s 185ms/step - loss: 3.1092 - val_loss: 3.3668\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 19s 189ms/step - loss: 3.0051 - val_loss: 3.3438\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 19s 187ms/step - loss: 2.9111 - val_loss: 3.2948\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 19s 186ms/step - loss: 2.8251 - val_loss: 3.2929\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.7406 - val_loss: 3.2697\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.6562 - val_loss: 3.2642\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.5758 - val_loss: 3.2413\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.4984 - val_loss: 3.2359\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.4175 - val_loss: 3.2399\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.3409 - val_loss: 3.2316\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 19s 185ms/step - loss: 2.2682 - val_loss: 3.2444\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.1911 - val_loss: 3.2572\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.1165 - val_loss: 3.2484\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 2.0434 - val_loss: 3.2430\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 19s 182ms/step - loss: 1.9731 - val_loss: 3.2614\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 19s 186ms/step - loss: 1.9018 - val_loss: 3.2725\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 20s 193ms/step - loss: 1.8340 - val_loss: 3.2759\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 20s 190ms/step - loss: 1.7637 - val_loss: 3.2864\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 19s 189ms/step - loss: 1.6963 - val_loss: 3.2947\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 19s 188ms/step - loss: 1.6292 - val_loss: 3.3122\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 19s 188ms/step - loss: 1.5624 - val_loss: 3.3239\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 19s 188ms/step - loss: 1.4997 - val_loss: 3.3444\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 19s 186ms/step - loss: 1.4369 - val_loss: 3.3692\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 19s 188ms/step - loss: 1.3708 - val_loss: 3.3905\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 19s 188ms/step - loss: 1.3113 - val_loss: 3.4125\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 20s 190ms/step - loss: 1.2502 - val_loss: 3.4270\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 20s 190ms/step - loss: 1.1922 - val_loss: 3.4510\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 20s 190ms/step - loss: 1.1341 - val_loss: 3.4632\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 20s 190ms/step - loss: 1.0774 - val_loss: 3.4935\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 19s 189ms/step - loss: 1.0219 - val_loss: 3.5197\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 19s 189ms/step - loss: 0.9700 - val_loss: 3.5437\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 20s 190ms/step - loss: 0.9158 - val_loss: 3.5465\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 19s 189ms/step - loss: 0.8657 - val_loss: 3.5647\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 20s 191ms/step - loss: 0.8159 - val_loss: 3.5972\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 21s 206ms/step - loss: 0.7695 - val_loss: 3.6131\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.7236 - val_loss: 3.6532\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.6792 - val_loss: 3.6690\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.6374 - val_loss: 3.6962\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 25s 243ms/step - loss: 0.5970 - val_loss: 3.7284\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.5572 - val_loss: 3.7474\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.5202 - val_loss: 3.7753\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 25s 246ms/step - loss: 0.4830 - val_loss: 3.7879\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 25s 245ms/step - loss: 0.4500 - val_loss: 3.8172\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.4179 - val_loss: 3.8413\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.3886 - val_loss: 3.8580\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 25s 245ms/step - loss: 0.3583 - val_loss: 3.8984\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.3299 - val_loss: 3.9288\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 25s 244ms/step - loss: 0.3061 - val_loss: 3.9525\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 24s 236ms/step - loss: 0.2809 - val_loss: 3.9844\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.2568 - val_loss: 4.0178\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.2342 - val_loss: 4.0557\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.2157 - val_loss: 4.0815\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.1966 - val_loss: 4.1083\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 19s 187ms/step - loss: 0.1805 - val_loss: 4.1158\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 19s 185ms/step - loss: 0.1640 - val_loss: 4.1377\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.1495 - val_loss: 4.1559\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.1356 - val_loss: 4.1813\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 19s 185ms/step - loss: 0.1223 - val_loss: 4.2031\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.1115 - val_loss: 4.2190\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.1010 - val_loss: 4.2451\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0914 - val_loss: 4.2561\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0833 - val_loss: 4.2828\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0746 - val_loss: 4.3108\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0676 - val_loss: 4.3368\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0606 - val_loss: 4.3524\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0555 - val_loss: 4.3652\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0501 - val_loss: 4.3902\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0461 - val_loss: 4.4067\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0422 - val_loss: 4.4310\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0379 - val_loss: 4.4381\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0349 - val_loss: 4.4632\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0325 - val_loss: 4.4776\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0297 - val_loss: 4.4939\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0264 - val_loss: 4.4910\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0247 - val_loss: 4.5103\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0232 - val_loss: 4.5315\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0212 - val_loss: 4.5378\n",
      "Epoch 80/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0196 - val_loss: 4.5548\n",
      "Epoch 81/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0176 - val_loss: 4.5912\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0172 - val_loss: 4.6051\n",
      "Epoch 83/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0157 - val_loss: 4.6097\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0143 - val_loss: 4.6386\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0140 - val_loss: 4.6604\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0131 - val_loss: 4.6678\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0120 - val_loss: 4.6823\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0118 - val_loss: 4.6968\n",
      "Epoch 89/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0111 - val_loss: 4.7114\n",
      "Epoch 90/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0104 - val_loss: 4.7289\n",
      "Epoch 91/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0099 - val_loss: 4.7510\n",
      "Epoch 92/100\n",
      "103/103 [==============================] - 19s 187ms/step - loss: 0.0099 - val_loss: 4.7553\n",
      "Epoch 93/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0092 - val_loss: 4.7562\n",
      "Epoch 94/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0086 - val_loss: 4.7473\n",
      "Epoch 95/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0079 - val_loss: 4.7804\n",
      "Epoch 96/100\n",
      "103/103 [==============================] - 19s 184ms/step - loss: 0.0080 - val_loss: 4.7989\n",
      "Epoch 97/100\n",
      "103/103 [==============================] - 19s 185ms/step - loss: 0.0078 - val_loss: 4.8064\n",
      "Epoch 98/100\n",
      "103/103 [==============================] - 20s 190ms/step - loss: 0.0073 - val_loss: 4.8130\n",
      "Epoch 99/100\n",
      "103/103 [==============================] - 19s 185ms/step - loss: 0.0064 - val_loss: 4.8193\n",
      "Epoch 100/100\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.0061 - val_loss: 4.8407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x268706b0940>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "34748a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('nmt_weights.h5')\n",
    "model.load_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "0be24217",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "0b391b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "9140e204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5086.,  7232., 15303.,  3035.,   866., 12354.,  6222.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.]], dtype=float32)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1\n",
    "test_gen=generate_batch(np.asarray([\"everything in these computers are really good\"]),y_train,batch_size=1)\n",
    "(q,_),_=next(test_gen)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "5d2c9ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input English sentence: and im earning more than the footballers wow\n",
      "Actual Hindi Translation:  और मैं फूटबाल खिलाडियों से ज्यादा कम रहा हूँ वाह \n",
      "Predicted Hindi Translation:  और मैं फूटबाल खिलाडियों से ज्यादा कम रहा हूँ वाह \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8eb34bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input English sentence: yamuna joins ganga at allahabad from the left side\n",
      "Actual Hindi Translation:  यमुना इलाहाबाद के निकट बायीं ओर से गंगा नदी में जा मिलती है। \n",
      "Predicted Hindi Translation:  यमुना इलाहाबाद के निकट बायीं ओर से गंगा नदी मे\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "b2252a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Input English sentence: i have spent my entire life\n",
      "Actual Hindi Translation:  मेरी सारी उम्र बीती है \n",
      "Predicted Hindi Translation:  मेरी सारी उम्र बीती है \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "b432ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Input English sentence: to some extent farooq is nervous about the ongoing secret talks between the hurriyat and delhi s nonofficial negotiators\n",
      "Actual Hindi Translation:  फारूक ह्र्रियत और दिल्ली के गैरसरकारी वार्ताकारों के बीच चलती बातचीत से कुछ बेचैन हैं \n",
      "Predicted Hindi Translation:  फारूक ह्र्रियत और दिल्ली के गैरसरकारी वार्ताकारो\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "1a1eb2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input English sentence: it was chic to be left wear kurtas and sport angst as an unshaven commitment\n",
      "Actual Hindi Translation:  कुर्ता पहनना दाढी रखना और आक्रोश जताना पक्की प्रतिबद्धता की निशानी थी \n",
      "Predicted Hindi Translation:  कुर्ता पहनना दाढी रखना और आक्रोश जताना पक्की प्रतिबद्धता\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "b2361176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted Hindi Translation:  ये प्रचार है जैसे कि हर क्षेत्रों में क्या ले \n"
     ]
    }
   ],
   "source": [
    "\n",
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "# print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "# print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0dfdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
